{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptual loss for SRCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6e220ac22c94991ad2fd5b9c48ccdae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2b05ce178fa4ff19422b48d84ba395f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_864dbd62e2f94252a7dc344d2c532c7a",
              "IPY_MODEL_eb447c4cf261480f92688b836b8e12ca"
            ]
          }
        },
        "a2b05ce178fa4ff19422b48d84ba395f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "864dbd62e2f94252a7dc344d2c532c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_774d9b51047b4e42b9a65b97f8e73e9e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fedc133957f4e28a9b6808e185be422"
          }
        },
        "eb447c4cf261480f92688b836b8e12ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6eb653d38f444402aa40e1ce4661a9c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [2:31:53&lt;00:00, 60.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5663e0c2bf2d43ac84125d24f43abeb9"
          }
        },
        "774d9b51047b4e42b9a65b97f8e73e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fedc133957f4e28a9b6808e185be422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6eb653d38f444402aa40e1ce4661a9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5663e0c2bf2d43ac84125d24f43abeb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-iZl2MNvcwr"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, h5_file):\n",
        "        super(TrainDataset, self).__init__()\n",
        "        self.h5_file = h5_file\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with h5py.File(self.h5_file, 'r') as f:\n",
        "            return np.expand_dims(f['lr'][idx] / 255., 0), np.expand_dims(f['hr'][idx] / 255., 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        with h5py.File(self.h5_file, 'r') as f:\n",
        "            return len(f['lr'])\n",
        "\n",
        "\n",
        "class EvalDataset(Dataset):\n",
        "    def __init__(self, h5_file):\n",
        "        super(EvalDataset, self).__init__()\n",
        "        self.h5_file = h5_file\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with h5py.File(self.h5_file, 'r') as f:\n",
        "            return np.expand_dims(f['lr'][str(idx)][:, :] / 255., 0), np.expand_dims(f['hr'][str(idx)][:, :] / 255., 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        with h5py.File(self.h5_file, 'r') as f:\n",
        "            return len(f['lr'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvzdCmuTvm1B"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class SRCNN(nn.Module):\n",
        "    def __init__(self, num_channels=1):\n",
        "        super(SRCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=9, padding=9 // 2)\n",
        "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=5 // 2)\n",
        "        self.conv3 = nn.Conv2d(32, num_channels, kernel_size=5, padding=5 // 2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwloaoqJv6PR"
      },
      "source": [
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def convert_rgb_to_y(img):\n",
        "    if type(img) == np.ndarray:\n",
        "        return 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
        "    elif type(img) == torch.Tensor:\n",
        "        if len(img.shape) == 4:\n",
        "            img = img.squeeze(0)\n",
        "        return 16. + (64.738 * img[0, :, :] + 129.057 * img[1, :, :] + 25.064 * img[2, :, :]) / 256.\n",
        "    else:\n",
        "        raise Exception('Unknown Type', type(img))\n",
        "\n",
        "\n",
        "def convert_rgb_to_ycbcr(img):\n",
        "    if type(img) == np.ndarray:\n",
        "        y = 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
        "        cb = 128. + (-37.945 * img[:, :, 0] - 74.494 * img[:, :, 1] + 112.439 * img[:, :, 2]) / 256.\n",
        "        cr = 128. + (112.439 * img[:, :, 0] - 94.154 * img[:, :, 1] - 18.285 * img[:, :, 2]) / 256.\n",
        "        return np.array([y, cb, cr]).transpose([1, 2, 0])\n",
        "    elif type(img) == torch.Tensor:\n",
        "        if len(img.shape) == 4:\n",
        "            img = img.squeeze(0)\n",
        "        y = 16. + (64.738 * img[0, :, :] + 129.057 * img[1, :, :] + 25.064 * img[2, :, :]) / 256.\n",
        "        cb = 128. + (-37.945 * img[0, :, :] - 74.494 * img[1, :, :] + 112.439 * img[2, :, :]) / 256.\n",
        "        cr = 128. + (112.439 * img[0, :, :] - 94.154 * img[1, :, :] - 18.285 * img[2, :, :]) / 256.\n",
        "        return torch.cat([y, cb, cr], 0).permute(1, 2, 0)\n",
        "    else:\n",
        "        raise Exception('Unknown Type', type(img))\n",
        "\n",
        "\n",
        "def convert_ycbcr_to_rgb(img):\n",
        "    if type(img) == np.ndarray:\n",
        "        r = 298.082 * img[:, :, 0] / 256. + 408.583 * img[:, :, 2] / 256. - 222.921\n",
        "        g = 298.082 * img[:, :, 0] / 256. - 100.291 * img[:, :, 1] / 256. - 208.120 * img[:, :, 2] / 256. + 135.576\n",
        "        b = 298.082 * img[:, :, 0] / 256. + 516.412 * img[:, :, 1] / 256. - 276.836\n",
        "        return np.array([r, g, b]).transpose([1, 2, 0])\n",
        "    elif type(img) == torch.Tensor:\n",
        "        if len(img.shape) == 4:\n",
        "            img = img.squeeze(0)\n",
        "        r = 298.082 * img[0, :, :] / 256. + 408.583 * img[2, :, :] / 256. - 222.921\n",
        "        g = 298.082 * img[0, :, :] / 256. - 100.291 * img[1, :, :] / 256. - 208.120 * img[2, :, :] / 256. + 135.576\n",
        "        b = 298.082 * img[0, :, :] / 256. + 516.412 * img[1, :, :] / 256. - 276.836\n",
        "        return torch.cat([r, g, b], 0).permute(1, 2, 0)\n",
        "    else:\n",
        "        raise Exception('Unknown Type', type(img))\n",
        "\n",
        "\n",
        "def calc_psnr(img1, img2):\n",
        "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "def create_loss_model(vgg, end_layer, use_maxpool=True, use_cuda=False):\n",
        "\n",
        "    vgg = copy.deepcopy(vgg)\n",
        "\n",
        "    model = nn.Sequential()\n",
        "\n",
        "    #if use_cuda:\n",
        "        #model.cuda(device_id=0)\n",
        "\n",
        "    i = 0\n",
        "    for layer in list(vgg):\n",
        "\n",
        "        if i > end_layer:\n",
        "            break\n",
        "\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            name = \"conv_\" + str(i)\n",
        "            model.add_module(name, layer)\n",
        "\n",
        "        if isinstance(layer, nn.ReLU):\n",
        "            name = \"relu_\" + str(i)\n",
        "            model.add_module(name, layer)\n",
        "\n",
        "        if isinstance(layer, nn.MaxPool2d):\n",
        "            name = \"pool_\" + str(i)\n",
        "            if use_maxpool:\n",
        "                model.add_module(name, layer)\n",
        "            else:\n",
        "                avgpool = nn.AvgPool2d(kernel_size=layer.kernel_size, stride=layer.stride, padding=layer.padding)\n",
        "                model.add_module(name, avgpool)\n",
        "        i += 1\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egXfzRQwwCdt",
        "outputId": "ff808dad-70cd-4959-cac7-8af5999a461e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d6e220ac22c94991ad2fd5b9c48ccdae",
            "a2b05ce178fa4ff19422b48d84ba395f",
            "864dbd62e2f94252a7dc344d2c532c7a",
            "eb447c4cf261480f92688b836b8e12ca",
            "774d9b51047b4e42b9a65b97f8e73e9e",
            "1fedc133957f4e28a9b6808e185be422",
            "6eb653d38f444402aa40e1ce4661a9c4",
            "5663e0c2bf2d43ac84125d24f43abeb9"
          ]
        }
      },
      "source": [
        "\n",
        "import os\n",
        "import copy\n",
        "import h5py\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "    seed = 123\n",
        "    learn_rate = 1e-4\n",
        "    tf = \"/content/drive/My Drive/DataSet/91-image_x3.h5\"\n",
        "    batch = 8\n",
        "    ef = \"/content/drive/My Drive/DataSet/Set5_x3.h5\"\n",
        "    ne = 100\n",
        "    out_dir = \"/content/output\"\n",
        "    scale = 3\n",
        "    cudnn.benchmark = True\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    model = SRCNN().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    vgg16 = models.vgg16(pretrained=True).features\n",
        "    \n",
        "    #vgg16.cuda(device_id=0);\n",
        "\n",
        "    vgg_loss = create_loss_model(vgg16, 8)\n",
        "\n",
        "    for param in vgg_loss.parameters():\n",
        "        param.requires_grad = True\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': model.conv1.parameters()},\n",
        "        {'params': model.conv2.parameters()},\n",
        "        {'params': model.conv3.parameters(), 'lr': learn_rate * 0.1}\n",
        "    ], lr=learn_rate)\n",
        "\n",
        "    train_dataset = TrainDataset(tf)\n",
        "    print(\"here\")\n",
        "    train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                                  batch_size=batch,\n",
        "                                  shuffle=True,\n",
        "                                  num_workers=8,\n",
        "                                  pin_memory=True,\n",
        "                                  drop_last=True)\n",
        "    eval_dataset = EvalDataset(ef)\n",
        "    eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
        "\n",
        "    best_weights = copy.deepcopy(model.state_dict())\n",
        "    best_epoch = 0\n",
        "    best_psnr = 0.0\n",
        "#mean = 0.485,0.456,0.406\n",
        "#std = 0.229,0.224,0.225\n",
        "    for epoch in range(ne):\n",
        "        model.train()\n",
        "        epoch_losses = AverageMeter()\n",
        "# Mean and std deviation for inputs\n",
        "        with tqdm(total=(len(train_dataset) - len(train_dataset) % batch)) as t:\n",
        "            t.set_description('epoch: {}/{}'.format(epoch, ne - 1))\n",
        "\n",
        "            for data in train_dataloader:\n",
        "                inputs, labels = data\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                preds = model(inputs)\n",
        "\n",
        "               \n",
        "                inputs = torch.cat((inputs,inputs,inputs),dim=1)                \n",
        "                vgg_loss_inp = vgg_loss(inputs)\n",
        "                labels = torch.cat((labels,labels,labels),dim=1)\n",
        "                vgg_loss_tgt = vgg_loss(labels)\n",
        "                loss = criterion(vgg_loss_inp, vgg_loss_tgt)\n",
        "                \n",
        "            new loss = \n",
        "\n",
        "                epoch_losses.update(loss.item(), len(inputs))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
        "                t.update(len(inputs))\n",
        "\n",
        "        torch.save(model.state_dict(), os.path.join(out_dir, 'epoch_{}.pth'.format(epoch)))\n",
        "\n",
        "        model.eval()\n",
        "        epoch_psnr = AverageMeter()\n",
        "\n",
        "        for data in eval_dataloader:\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds = model(inputs).clamp(0.0, 1.0)\n",
        "\n",
        "            epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
        "\n",
        "        print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
        "\n",
        "        if epoch_psnr.avg > best_psnr:\n",
        "            best_epoch = epoch\n",
        "            best_psnr = epoch_psnr.avg\n",
        "            best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
        "    torch.save(best_weights, os.path.join(out_dir, 'best.pth'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6e220ac22c94991ad2fd5b9c48ccdae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "here\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0/99: 100%|██████████| 21880/21880 [15:57<00:00, 22.84it/s, loss=0.399684]\n",
            "epoch: 1/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1/99: 100%|██████████| 21880/21880 [10:10<00:00, 35.85it/s, loss=0.399573]\n",
            "epoch: 2/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 2/99: 100%|██████████| 21880/21880 [10:13<00:00, 35.66it/s, loss=0.399698]\n",
            "epoch: 3/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 3/99: 100%|██████████| 21880/21880 [10:12<00:00, 35.74it/s, loss=0.399719]\n",
            "epoch: 4/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 4/99: 100%|██████████| 21880/21880 [10:06<00:00, 36.09it/s, loss=0.399677]\n",
            "epoch: 5/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 5/99: 100%|██████████| 21880/21880 [10:07<00:00, 36.00it/s, loss=0.399666]\n",
            "epoch: 6/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 6/99: 100%|██████████| 21880/21880 [10:08<00:00, 35.95it/s, loss=0.399699]\n",
            "epoch: 7/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 7/99: 100%|██████████| 21880/21880 [10:07<00:00, 36.03it/s, loss=0.399673]\n",
            "epoch: 8/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 8/99: 100%|██████████| 21880/21880 [10:24<00:00, 35.05it/s, loss=0.399662]\n",
            "epoch: 9/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 9/99: 100%|██████████| 21880/21880 [10:33<00:00, 34.53it/s, loss=0.399672]\n",
            "epoch: 10/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 10/99: 100%|██████████| 21880/21880 [10:28<00:00, 34.83it/s, loss=0.399644]\n",
            "epoch: 11/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 11/99: 100%|██████████| 21880/21880 [10:35<00:00, 34.45it/s, loss=0.399699]\n",
            "epoch: 12/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 12/99: 100%|██████████| 21880/21880 [10:45<00:00, 33.88it/s, loss=0.399710]\n",
            "epoch: 13/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 13/99: 100%|██████████| 21880/21880 [10:19<00:00, 35.30it/s, loss=0.399698]\n",
            "epoch: 14/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 14/99: 100%|██████████| 21880/21880 [10:14<00:00, 35.61it/s, loss=0.399673]\n",
            "epoch: 15/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 15/99: 100%|██████████| 21880/21880 [10:15<00:00, 35.57it/s, loss=0.399711]\n",
            "epoch: 16/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 16/99: 100%|██████████| 21880/21880 [10:12<00:00, 35.71it/s, loss=0.399696]\n",
            "epoch: 17/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 17/99: 100%|██████████| 21880/21880 [10:11<00:00, 35.80it/s, loss=0.399719]\n",
            "epoch: 18/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 18/99: 100%|██████████| 21880/21880 [10:13<00:00, 35.65it/s, loss=0.399685]\n",
            "epoch: 19/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 19/99: 100%|██████████| 21880/21880 [10:10<00:00, 35.82it/s, loss=0.399677]\n",
            "epoch: 20/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 20/99: 100%|██████████| 21880/21880 [10:15<00:00, 35.58it/s, loss=0.399691]\n",
            "epoch: 21/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 21/99: 100%|██████████| 21880/21880 [10:12<00:00, 35.72it/s, loss=0.399692]\n",
            "epoch: 22/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 22/99: 100%|██████████| 21880/21880 [10:12<00:00, 35.72it/s, loss=0.399673]\n",
            "epoch: 23/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 23/99: 100%|██████████| 21880/21880 [10:11<00:00, 35.75it/s, loss=0.399699]\n",
            "epoch: 24/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 24/99: 100%|██████████| 21880/21880 [10:20<00:00, 35.24it/s, loss=0.399718]\n",
            "epoch: 25/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 25/99: 100%|██████████| 21880/21880 [10:22<00:00, 35.14it/s, loss=0.399614]\n",
            "epoch: 26/99:   0%|          | 0/21880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "eval psnr: 6.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 26/99:  42%|████▏     | 9104/21880 [04:17<06:03, 35.13it/s, loss=0.397980]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dnrtCD5_63p"
      },
      "source": [
        "TEST (UNMODIFIED)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjLqeMDs9Xci"
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import PIL.Image as pil_image\n",
        "\n",
        "from models import SRCNN\n",
        "from utils import convert_rgb_to_ycbcr, convert_ycbcr_to_rgb, calc_psnr\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights-file', type=str, required=True)\n",
        "    parser.add_argument('--image-file', type=str, required=True)\n",
        "    parser.add_argument('--scale', type=int, default=3)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    cudnn.benchmark = True\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = SRCNN().to(device)\n",
        "\n",
        "    state_dict = model.state_dict()\n",
        "    for n, p in torch.load(args.weights_file, map_location=lambda storage, loc: storage).items():\n",
        "        if n in state_dict.keys():\n",
        "            state_dict[n].copy_(p)\n",
        "        else:\n",
        "            raise KeyError(n)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    image = pil_image.open(args.image_file).convert('RGB')\n",
        "\n",
        "    image_width = (image.width // args.scale) * args.scale\n",
        "    image_height = (image.height // args.scale) * args.scale\n",
        "    image = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
        "    image = image.resize((image.width // args.scale, image.height // args.scale), resample=pil_image.BICUBIC)\n",
        "    image = image.resize((image.width * args.scale, image.height * args.scale), resample=pil_image.BICUBIC)\n",
        "    image.save(args.image_file.replace('.', '_bicubic_x{}.'.format(args.scale)))\n",
        "\n",
        "    image = np.array(image).astype(np.float32)\n",
        "    ycbcr = convert_rgb_to_ycbcr(image)\n",
        "\n",
        "    y = ycbcr[..., 0]\n",
        "    y /= 255.\n",
        "    y = torch.from_numpy(y).to(device)\n",
        "    y = y.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(y).clamp(0.0, 1.0)\n",
        "\n",
        "    psnr = calc_psnr(y, preds)\n",
        "    print('PSNR: {:.2f}'.format(psnr))\n",
        "\n",
        "    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
        "\n",
        "    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
        "    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
        "    output = pil_image.fromarray(output)\n",
        "    output.save(args.image_file.replace('.', '_srcnn_x{}.'.format(args.scale)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}